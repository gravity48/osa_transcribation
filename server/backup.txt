WORK_DIR = '/media/gravity/Data/PycharmProjects/transcribing_web'
    kwargs = {
        'server': '192.168.0.137',
        'port': '3050',
        'db_name': 'd:\\databases\\speaker2.ibs',
        'login': 'sysdba',
        'password': 'masterkey',
        'db_system': 'Interbase',
        'charset': 'WIN1251',
        'period_from': '2021-09-01 00:00',
        'period_to': '2022-10-31 00:00',
        'models': [{'path': f'{WORK_DIR}/models/vosk-model-small-ru-0.22', 'name': 'RU'},
                   {'path': f'{WORK_DIR}/models/vosk-model-small-uk-v3-small', 'name': 'UA'}],
        'spk_model': f'{WORK_DIR}/models/vosk-model-spk-0.4',
        'log': '/media/gravity/Data/PycharmProjects/transcribing_web/logfiles/123.log',
        'write_result': True,
        'settings_db_login': 'django',
        'settings_db_pwd': 'django',
        'settings_db_host': '127.0.0.1',
        'settings_db_name': 'osa_transcribing',
        'settings_record_id': 35,
        'time_processing': 200,
        'thread_count': 5,
    }

    postwork_db = PostworkDB(kwargs['server'], kwargs['port'], kwargs['login'], kwargs['password'],
                             kwargs['db_name'], kwargs['db_system'], kwargs['charset'])
    postwork_db.unmark_all_records(1)

    transcribing_task = TranscribingTask(kwargs)
    transcribing_task.run_speaker_identification_process(1,
                                                         '/media/gravity/Data/PycharmProjects/transcribing_web/transcribing/64.wav')
    # transcribing_task.run_transcribing_process(2)
    # transcribing_task.run_transcribing_process(2)
    '''
    decoder_speech = transcribing_task.run()

    wav_binary = io.BytesIO(decoder_speech[1])
    wf = wave.open(wav_binary, 'rb')
    print(wf.getnchannels())
    print(wf.getsampwidth())
    print(wf.getcomptype())
    print(wf.getframerate())

    con = idb.connect(dsn='172.16.71.134:c:\\Databases\\TESTOVAYA_EMPTY.IBS', user='sysdba', password='masterkey',
                      charset='WIN1251', fb_library_name='/lib/i386-linux-gnu/libgds.so')

    cur = con.cursor()
    # Execute the SELECT statement:
    cur.execute("select * from spr_event")
    result = cur.fetchall()
    print(result)
    if not os.path.exists("model-ru"):
        print(
            "Please download the model from https://github.com/alphacep/kaldi-android-demo/releases and unpack as 'model-en' in the current folder.")
        exit(1)
    '''


        def run(self):
        logger.info('Run transcribing task')
        logger.info('Train model')
        transcribing_models = []
        for model in self.models:
            transcribing_models.append(ModelTuple(TranscribingModel(model['path']), model['name']))
            transcribing_models[-1].model.train()
        logger.info('Try read data from database')
        while True:
            records_list = self.postwork_db_local.read_records_list(self.period_to, self.period_from)
            record_count = len(records_list)
            logger.info(f'Read {record_count} records')
            threads = list()
            for thread_id in range(self.thread_count):
                threads.append(threading.Thread(target=self._thread_start,
                                                args=(records_list, thread_id, record_count)))
                threads[-1].start()
            for thread in threads:
                thread.join()
            if datetime.now() > self.period_to:
                break
            time.sleep(self.SLEEP_TIME)
        return True

    def run_with_thread(self, thread_count):
        logger.info('Run transcribing thread task')
        logger.info('Read data from database')
        while datetime.now() < self.period_to:
            threads = []
            records_list: list = self.postwork_db_local.read_records_list(self.period_to, self.period_from,
                                                                          self.TASK_LIMIT)
            for thread_id in range(thread_count):
                threads.append(threading.Thread(target=self._thread_start,
                                                args=(records_list, thread_id)))
                threads[-1].start()
            for thread in threads:
                thread.join()
        logger.info('Wait files')
        time.sleep(self.SLEEP_TIME)

        logger.bind().info('Run transcribing process')
        logger.info('Read data from database')
        transcribing_models = []
        for model in self.models:
            transcribing_models.append(ModelTuple(TranscribingModel(model['path']), model['name']))
            transcribing_models[-1].model.train()
        logger.info('Train transcribing models success')
        records_list, record_count = self.db.read_records_list(self.period_to, self.period_from,
                                                               self.TASK_LIMIT)
        self.settings_db.write_record_count(self.settings_record_id, record_count)
        stop_event = threading.Event()
        logger.info('Run control thread')
        processes = []
        process_control_thread = threading.Thread(name='process_control', target=self.control_process,
                                                  args=(stop_event, self.time_processing, processes))
        process_control_thread.start()
        logger.info('Start process')
        while records_list:
            record = records_list.pop(-1)
            logger.info(f'Handle record id: {record[0]}')
            while 1:
                if self.settings_db.get_force_stop(self.settings_record_id):
                    return
                if len(processes) < process_count:
                    work_process = WorkProcess(multiprocessing.Process(target=self._transcribing_proj_process,
                                                                       args=(record, transcribing_models)),
                                               datetime.now())
                    work_process.process.start()
                    processes.append(work_process)
                    break
                if self.write_result:
                    percent = int(((record_count - len(records_list)) * 100) / record_count)
                    self.settings_db.write_percent(self.settings_record_id, percent, record[0])
            if not records_list:
                records_list, record_count = self.postwork_db_local.read_records_list(self.period_to, self.period_from,
                                                                                      self.TASK_LIMIT)
        logger.info('Wait files')
        stop_event.set()
        process_control_thread.join()


            def _thread_start(self, records_list: list, thread_id, record_count):
        logger.info(f'Run transcribing thread: {thread_id}')
        logger.info(f'Train model thread: {thread_id}')
        transcribing_models = []
        for model in self.models:
            transcribing_models.append(ModelTuple(TranscribingModel(model['path']), model['name']))
            transcribing_models[-1].model.train()
        self.settings_db.write_record_count(self.settings_record_id, record_count)
        while len(records_list):
            record_id = records_list.pop(-1)
            logger.info(f' Handle record id: {record_id[0]} thread: {thread_id}')
            self.handle_record(record_id[0], transcribing_models)
            print(record_id[0])
            if self.write_result:
                percent = int(((record_count - len(records_list)) * 100) / record_count)
                self.settings_db.write_percent(self.settings_record_id, percent, record_id[0])

                    def _transcribing_proj_process(self, record, models):
        self.handle_record(record[0], models)
        pass